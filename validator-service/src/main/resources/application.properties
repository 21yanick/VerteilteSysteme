############################################################
## Server Config
############################################################
quarkus.http.port=8083

############################################################
## Kafka Configuration
############################################################
mp.messaging.connector.smallrye-kafka.bootstrap.servers=kafka:9092

# Kafka Topic / Channel Configuration
mp.messaging.incoming.validation-request-in.connector=smallrye-kafka
mp.messaging.incoming.validation-request-in.topic=blog-validation-requests
mp.messaging.incoming.validation-request-in.value.deserializer=ch.hftm.messaging.ValidationRequestDeserializer
mp.messaging.incoming.validation-request-in.group.id=blog-validator-group

mp.messaging.outgoing.validation-response-out.connector=smallrye-kafka
mp.messaging.outgoing.validation-response-out.topic=blog-validation-responses
mp.messaging.outgoing.validation-response-out.value.serializer=io.quarkus.kafka.client.serialization.ObjectMapperSerializer

############################################################
## LangChain4J / OpenAI Integration 
############################################################
# OpenAI API-Key wird aus Umgebungsvariable geladen
# Umgebungsvariable sollte im Docker Container gesetzt sein
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY:default-key}
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o-mini
quarkus.langchain4j.openai.chat-model.temperature=0.7
quarkus.langchain4j.openai.chat-model.timeout=30s
quarkus.langchain4j.openai.log-requests=true
quarkus.langchain4j.openai.log-responses=true